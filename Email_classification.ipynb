{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae47ae9-ecc2-4294-be36-613f8081c483",
   "metadata": {},
   "source": [
    "## NLP.Final Project: Email classification\n",
    "### Creator: Meshalkin Nikita"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a76bb30-aa84-4f9a-a270-c01d141146f9",
   "metadata": {},
   "source": [
    "Description of work: In this work I will solve the problem of binary classification of messages using the BERT neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25751539-a1d8-4cb1-8243-75f57a712356",
   "metadata": {},
   "source": [
    "#### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9c3985-dd60-41d9-9504-34bd5c46a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe5c15-b070-4a11-bc28-0eb48c4a02e7",
   "metadata": {},
   "source": [
    "#### 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a74fc1f-6d4a-405e-b521-25ac2ddcbc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro...\n",
       "5      1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6      0  Even my brother is not like to speak with me. ...\n",
       "7      0  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8      1  WINNER!! As a valued network customer you have...\n",
       "9      1  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spamdata_v2.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbbcd27-6ec8-41e8-92d7-83535235a835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737b2c45-cc4b-4995-9012-806c6d9240c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.865937\n",
       "1    0.134063\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dddfdf-f3ca-4deb-8451-b83204428ca1",
   "metadata": {},
   "source": [
    "#### 3. Split train dataset into train, validation and test sets\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad1c0b9-e7cb-4f45-b67c-ef744762b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state=2023, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2023, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f05a345-931a-4323-8135-0e8d92fd2148",
   "metadata": {},
   "source": [
    "#### 4. Load BERT model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b396083-80f9-4afa-97bd-5a39b8dda18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff95f362-320b-47a5-9201-6abbc1df9c17",
   "metadata": {},
   "source": [
    "Let's look on our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab52cb41-892e-4053-9e0f-c4102b66d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "text = [\"This is a final project\", \"I will fine-tune a bertmodel\"]\n",
    "\n",
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3bf58e-89e3-457d-957f-a16a8fc4f701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 2345, 2622, 102, 0, 0, 0, 0], [101, 1045, 2097, 2986, 1011, 8694, 1037, 14324, 5302, 9247, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# output\n",
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a824d42-8cd8-4e68-ae96-17b8d7ae3457",
   "metadata": {},
   "source": [
    "#### 5. Prepare data, tokenize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829da21d-d2da-4426-a921-faf35d9bbe20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ceeeff-3a94-4391-a6c2-dabc52ec7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 25\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab028fb-e9ce-4dca-afa4-2fb777b11da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d48825-f4e8-4a2c-9e69-625095b232d5",
   "metadata": {},
   "source": [
    "Let's convert Integer Sequences to Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68ce3378-5e0c-445d-bdc3-1a1639d2705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e5b14-63f9-44aa-b430-72a835a5aa65",
   "metadata": {},
   "source": [
    "Let's define DataLoaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20375c65-9187-4167-8d94-30a89ab0b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e3ce5-5772-47fe-9312-c9b49f7e5309",
   "metadata": {},
   "source": [
    "#### 6. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be960be1-ccdb-4d66-bee4-8419dcf5162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a17f47-4e96-4795-9732-84a563175dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f35a68-763c-4dfe-a575-5736e86c8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5efc021-84e0-4255-b396-413015c91265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch_env\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ead3f2-36e4-4659-a92b-5162fcd90311",
   "metadata": {},
   "source": [
    "Find class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ec27869-ce59-474a-a06c-17518ea82579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57743559, 3.72848948])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight(class_weight = 'balanced', classes = np.unique(train_labels), y = train_labels)\n",
    "\n",
    "class_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d552688-831e-4689-bf4c-39b6f9e0c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc89780f-e37d-4c5d-b92a-b26fc37fb2b5",
   "metadata": {},
   "source": [
    "#### 7. Fine-tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c8702af-6233-4553-9670-2e6e8cc2a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    \"Convert a tensor to a numpy array.\"\n",
    "    return (lambda o: o.data.cpu().numpy(), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e569110-d8a1-43e8-bbca-02a511ec46f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92c36542-ab73-471e-995c-35d058e1a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1bd103-f6da-47aa-974c-1a2d7e54f183",
   "metadata": {},
   "source": [
    "Start model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8115c9c-d459-497c-8443-bca076a1422c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.323\n",
      "Validation Loss: 0.193\n",
      "\n",
      " Epoch 2 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.252\n",
      "Validation Loss: 0.207\n",
      "\n",
      " Epoch 3 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.269\n",
      "Validation Loss: 0.155\n",
      "\n",
      " Epoch 4 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.226\n",
      "Validation Loss: 0.216\n",
      "\n",
      " Epoch 5 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.242\n",
      "Validation Loss: 0.147\n",
      "\n",
      " Epoch 6 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.270\n",
      "Validation Loss: 0.115\n",
      "\n",
      " Epoch 7 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.267\n",
      "Validation Loss: 0.223\n",
      "\n",
      " Epoch 8 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.226\n",
      "Validation Loss: 0.113\n",
      "\n",
      " Epoch 9 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.233\n",
      "Validation Loss: 0.117\n",
      "\n",
      " Epoch 10 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.218\n",
      "Validation Loss: 0.157\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f2748-213b-4eb6-98de-664a6374b1a8",
   "metadata": {},
   "source": [
    "#### 8. Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c7fd7e7-814c-40fc-ae8d-a94081183593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8cd17-0b68-40b0-8c57-48abace3d522",
   "metadata": {},
   "source": [
    "#### 9. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1878c6ed-60f0-4dc1-a37e-78dc6f8ab519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "333807d9-8873-41b9-ae3e-802b96db1a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       724\n",
      "           1       0.90      0.91      0.91       112\n",
      "\n",
      "    accuracy                           0.97       836\n",
      "   macro avg       0.94      0.95      0.95       836\n",
      "weighted avg       0.97      0.97      0.97       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d5bc08e-a4fa-41ae-b126-d56848436b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>713</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "row_0          \n",
       "0      713   11\n",
       "1       10  102"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(test_y, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
